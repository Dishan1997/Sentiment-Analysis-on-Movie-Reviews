{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SC_Movie_Reviwer.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uwArzCBTm-Js"
      },
      "source": [
        "# Project on \n",
        "## **Sentiment Analysis On Movie Reviews**\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SOHPnUk8PzPI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57d387ea-bb75-40a5-f6d4-03c16d347ed0"
      },
      "source": [
        "!pip install pyprind\n",
        "!pip install torch==1.6.0 torchvision==0.7.0 torchtext==0.7.0"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyprind in /usr/local/lib/python3.7/dist-packages (2.11.2)\n",
            "Requirement already satisfied: torch==1.6.0 in /usr/local/lib/python3.7/dist-packages (1.6.0)\n",
            "Requirement already satisfied: torchvision==0.7.0 in /usr/local/lib/python3.7/dist-packages (0.7.0)\n",
            "Requirement already satisfied: torchtext==0.7.0 in /usr/local/lib/python3.7/dist-packages (0.7.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from torch==1.6.0) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.6.0) (1.19.5)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.7.0) (7.0.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext==0.7.0) (2.23.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from torchtext==0.7.0) (0.1.95)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext==0.7.0) (4.41.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.7.0) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.7.0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.7.0) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.7.0) (1.24.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uLF4_YgBcsil",
        "outputId": "9115e031-5588-4fc2-abc0-345ef9fc1cf3"
      },
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "import torchtext\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "import pyprind\n",
        "#%matplotlib inline  \n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O8D71x8eNW-O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "acec3c3c-3b81-4835-bf43-63fe1ecd27e4"
      },
      "source": [
        "is_cuda = torch.cuda.is_available()\n",
        "print(\"Cuda Status on system is {}\".format(is_cuda))\n",
        "print(torch.cuda.get_device_name())"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cuda Status on system is True\n",
            "Tesla T4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z4VAg5nUrUIX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "395552b8-3624-4a6d-b15e-1d9b95449328"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fg2bM8DbRy2E"
      },
      "source": [
        "Preparation  of Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VnUcPHZWR6Iy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "b5e633d8-0ae4-4e8e-c862-5ba9c892bb84"
      },
      "source": [
        "df = pd.read_csv(\"/content/drive/MyDrive/Movie/movie_review.csv\")\n",
        "df"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fold_id</th>\n",
              "      <th>cv_tag</th>\n",
              "      <th>html_id</th>\n",
              "      <th>sent_id</th>\n",
              "      <th>text</th>\n",
              "      <th>tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>cv000</td>\n",
              "      <td>29590</td>\n",
              "      <td>0</td>\n",
              "      <td>films adapted from comic books have had plenty...</td>\n",
              "      <td>pos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>cv000</td>\n",
              "      <td>29590</td>\n",
              "      <td>1</td>\n",
              "      <td>for starters , it was created by alan moore ( ...</td>\n",
              "      <td>pos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>cv000</td>\n",
              "      <td>29590</td>\n",
              "      <td>2</td>\n",
              "      <td>to say moore and campbell thoroughly researche...</td>\n",
              "      <td>pos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>cv000</td>\n",
              "      <td>29590</td>\n",
              "      <td>3</td>\n",
              "      <td>the book ( or \" graphic novel , \" if you will ...</td>\n",
              "      <td>pos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>cv000</td>\n",
              "      <td>29590</td>\n",
              "      <td>4</td>\n",
              "      <td>in other words , don't dismiss this film becau...</td>\n",
              "      <td>pos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64715</th>\n",
              "      <td>9</td>\n",
              "      <td>cv999</td>\n",
              "      <td>14636</td>\n",
              "      <td>20</td>\n",
              "      <td>that lack of inspiration can be traced back to...</td>\n",
              "      <td>neg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64716</th>\n",
              "      <td>9</td>\n",
              "      <td>cv999</td>\n",
              "      <td>14636</td>\n",
              "      <td>21</td>\n",
              "      <td>like too many of the skits on the current inca...</td>\n",
              "      <td>neg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64717</th>\n",
              "      <td>9</td>\n",
              "      <td>cv999</td>\n",
              "      <td>14636</td>\n",
              "      <td>22</td>\n",
              "      <td>after watching one of the \" roxbury \" skits on...</td>\n",
              "      <td>neg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64718</th>\n",
              "      <td>9</td>\n",
              "      <td>cv999</td>\n",
              "      <td>14636</td>\n",
              "      <td>23</td>\n",
              "      <td>bump unsuspecting women , and . . . that's all .</td>\n",
              "      <td>neg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64719</th>\n",
              "      <td>9</td>\n",
              "      <td>cv999</td>\n",
              "      <td>14636</td>\n",
              "      <td>24</td>\n",
              "      <td>after watching _a_night_at_the_roxbury_ , you'...</td>\n",
              "      <td>neg</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>64720 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       fold_id cv_tag  ...                                               text  tag\n",
              "0            0  cv000  ...  films adapted from comic books have had plenty...  pos\n",
              "1            0  cv000  ...  for starters , it was created by alan moore ( ...  pos\n",
              "2            0  cv000  ...  to say moore and campbell thoroughly researche...  pos\n",
              "3            0  cv000  ...  the book ( or \" graphic novel , \" if you will ...  pos\n",
              "4            0  cv000  ...  in other words , don't dismiss this film becau...  pos\n",
              "...        ...    ...  ...                                                ...  ...\n",
              "64715        9  cv999  ...  that lack of inspiration can be traced back to...  neg\n",
              "64716        9  cv999  ...  like too many of the skits on the current inca...  neg\n",
              "64717        9  cv999  ...  after watching one of the \" roxbury \" skits on...  neg\n",
              "64718        9  cv999  ...   bump unsuspecting women , and . . . that's all .  neg\n",
              "64719        9  cv999  ...  after watching _a_night_at_the_roxbury_ , you'...  neg\n",
              "\n",
              "[64720 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WFDT37BrnbO3"
      },
      "source": [
        "Shape of dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DpSp1ZOHfn4I",
        "outputId": "dcb7bc1d-1800-4ec7-a791-955914635c59"
      },
      "source": [
        "print(df.shape)\n",
        "df=df.dropna()\n",
        "print(df.shape)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(64720, 6)\n",
            "(64720, 6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "decdpN-LnlC9"
      },
      "source": [
        "Replacing the 'positive' tag with 1 and 'negative' with 0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DcV3UDc7fuFS"
      },
      "source": [
        "df[\"tag\"].replace({\"pos\":int(1),\"neg\":int(0)},inplace=True) \n",
        "X=df['text']\n",
        "y=df['tag']"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y0KeT0lYVLY3"
      },
      "source": [
        "Splitting the Test Train Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E9gsleHjSigB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "692af09c-1956-44f0-e2ab-7180177888a6"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.10, random_state=42)\n",
        "X_train,X_valid,y_train,y_valid=train_test_split(X_train, y_train, test_size=0.10, random_state=42)\n",
        "\n",
        "print(f'Size of Train set {X_train.shape}\\nSize of Test set {X_test.shape}\\nSize of valid set {X_valid.shape}\\n')"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of Train set (52423,)\n",
            "Size of Test set (6472,)\n",
            "Size of valid set (5825,)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hNs9NzqOdI48",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6b719ed-ec51-4442-aa51-859587baebb1"
      },
      "source": [
        "train = pd.concat([X_train, y_train], axis=1)\n",
        "print(train.shape)\n",
        "\n",
        "test = pd.concat([X_test, y_test], axis=1)\n",
        "print(test.shape)\n",
        "\n",
        "valid = pd.concat([X_valid, y_valid], axis=1)\n",
        "print(valid.shape)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(52423, 2)\n",
            "(6472, 2)\n",
            "(5825, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6FRJTWrguFVu"
      },
      "source": [
        "train.to_csv(\"/content/drive/My Drive/train.csv\", index=False)\n",
        "test.to_csv(\"/content/drive/My Drive/test.csv\", index=False)\n",
        "valid.to_csv(\"/content/drive/My Drive/valid.csv\", index=False)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XSNYdimrvS4t"
      },
      "source": [
        "del df,train, test, valid, X_train, y_train,X_valid,y_valid, X_test, y_test"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8u_FG05davsD"
      },
      "source": [
        "Tokenizing Dataset and using Pytorchtext\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ckuEDBgcWb-f"
      },
      "source": [
        "def tokenizer(text):\n",
        "    return [tok for tok in nltk.word_tokenize(text)]"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KlDbfcGJbdGb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3768a43-9758-449c-df4f-9696c35bd6a8"
      },
      "source": [
        "from torchtext import data\n",
        "TEXT = data.Field(sequential=True, tokenize=tokenizer,include_lengths = True)\n",
        "LABEL = data.LabelField(dtype=torch.float, sequential=False)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchtext/data/field.py:150: UserWarning: Field class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
            "  warnings.warn('{} class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.'.format(self.__class__.__name__), UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/torchtext/data/field.py:150: UserWarning: LabelField class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
            "  warnings.warn('{} class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SREbLYoYbqBI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d933deda-0725-47c3-9620-a697645bbf2e"
      },
      "source": [
        "train_data, valid_data, test_data = data.TabularDataset.splits(\n",
        "    path=\"/content/drive/My Drive/\", train=\"train.csv\", \n",
        "    validation=\"valid.csv\", test=\"test.csv\",format=\"csv\", skip_header=True, \n",
        "    fields=[('text', TEXT), ('tag', LABEL)]\n",
        ")\n",
        "#change "
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchtext/data/example.py:68: UserWarning: Example class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
            "  warnings.warn('Example class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.', UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/torchtext/data/example.py:78: UserWarning: Example class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
            "  warnings.warn('Example class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.', UserWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-V_qsNSleqbD"
      },
      "source": [
        "TEXT.build_vocab(train_data, vectors=torchtext.vocab.Vectors(\"/content/drive/My Drive/Movie/glove.840B.300d.txt\"), \n",
        "                 max_size=50000)\n",
        "LABEL.build_vocab(train_data)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1cFf112fnzTL"
      },
      "source": [
        "# For Setting1:\n",
        "**Hyperparameters:**\n",
        "\n",
        "\n",
        "*   Epoch number=5\n",
        "*   Learning rate=0.001\n",
        "*   batch size= 8\n",
        "*   Number of nodes in hidden layer= 100\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kcgNR4crcItj"
      },
      "source": [
        "# Hyperparameters\n",
        "num_epochs = 5\n",
        "learning_rate = 0.001\n",
        "\n",
        "INPUT_DIM = len(TEXT.vocab)\n",
        "EMBEDDING_DIM = 300\n",
        "HIDDEN_DIM = 100\n",
        "OUTPUT_DIM = 1\n",
        "#N_LAYERS = 2\n",
        "BIDIRECTIONAL = True\n",
        "DROPOUT = 0.1\n",
        "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token] # padding\n",
        "BATCH_SIZE = 8"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gtM0FkIBvpIm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0c068d1-be83-4e0e-eee5-c9edd261aefe"
      },
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)\n",
        "# keep in mind the sort_key option \n",
        "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
        "    (train_data, valid_data, test_data), sort_key=lambda x: len(x.text),sort_within_batch = True,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    device=device)"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchtext/data/iterator.py:48: UserWarning: BucketIterator class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
            "  warnings.warn('{} class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9s65OXqhhQXW"
      },
      "source": [
        "class LSTM_net(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim,\n",
        "                 bidirectional, dropout, pad_idx):\n",
        "        \n",
        "        super().__init__()\n",
        "        \n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx = pad_idx)\n",
        "        \n",
        "        self.rnn = nn.LSTM(embedding_dim, \n",
        "                           hidden_dim, \n",
        "                           bidirectional=bidirectional, \n",
        "                           dropout=dropout)\n",
        "        \n",
        "        self.fc1 = nn.Linear(hidden_dim * 2, hidden_dim)\n",
        "        \n",
        "        self.fc2 = nn.Linear(hidden_dim, 1)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, text, text_lengths):\n",
        "        \n",
        "        # text = [sent len, batch size]\n",
        "        \n",
        "        embedded = self.embedding(text)\n",
        "        \n",
        "        # embedded = [sent len, batch size, emb dim]\n",
        "        \n",
        "        #pack sequence\n",
        "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, text_lengths)\n",
        "        \n",
        "        packed_output, (hidden, cell) = self.rnn(packed_embedded)\n",
        "        \n",
        "        #unpack sequence\n",
        "        # output, output_lengths = nn.utils.rnn.pad_packed_sequence(packed_output)\n",
        "\n",
        "        # output = [sent len, batch size, hid dim * num directions]\n",
        "        # output over padding tokens are zero tensors\n",
        "        \n",
        "        # hidden = [num layers * num directions, batch size, hid dim]\n",
        "        # cell = [num layers * num directions, batch size, hid dim]\n",
        "        \n",
        "        # concat the final forward (hidden[-2,:,:]) and backward (hidden[-1,:,:]) hidden layers\n",
        "        # and apply dropout\n",
        "        \n",
        "        hidden = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1))\n",
        "        output = self.fc1(hidden)\n",
        "        output = self.dropout(self.fc2(output))\n",
        "                \n",
        "        #hidden = [batch size, hid dim * num directions]\n",
        "            \n",
        "        return output"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wSDLbE8lhafm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b53225bb-59fc-470c-99a2-e6fce8b0e0cb"
      },
      "source": [
        "#creating instance of our LSTM_net class\n",
        "\n",
        "model = LSTM_net(INPUT_DIM, \n",
        "            EMBEDDING_DIM, \n",
        "            HIDDEN_DIM, \n",
        "            OUTPUT_DIM,  \n",
        "            BIDIRECTIONAL, \n",
        "            DROPOUT, \n",
        "            PAD_IDX)"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:60: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aEZNYmFIigH3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65c5665d-41d2-477e-e823-b449e4115e4d"
      },
      "source": [
        "pretrained_embeddings = TEXT.vocab.vectors\n",
        "\n",
        "print(pretrained_embeddings.shape)\n",
        "model.embedding.weight.data.copy_(pretrained_embeddings)"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([42704, 300])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "        [-0.0828,  0.6720, -0.1499,  ..., -0.1918, -0.3785, -0.0659],\n",
              "        ...,\n",
              "        [-0.3498,  0.4714,  0.3338,  ...,  0.2062,  0.1383,  0.1018],\n",
              "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "        [ 0.1034,  0.0618, -0.3565,  ..., -0.0621, -0.5939, -0.1527]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JUb6AC7Ji-jO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab7ec577-f24f-4b20-d3aa-3cca6459772e"
      },
      "source": [
        "#  to initiaise padded to zeros\n",
        "model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)\n",
        "\n",
        "print(model.embedding.weight.data)"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [-0.0828,  0.6720, -0.1499,  ..., -0.1918, -0.3785, -0.0659],\n",
            "        ...,\n",
            "        [-0.3498,  0.4714,  0.3338,  ...,  0.2062,  0.1383,  0.1018],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.1034,  0.0618, -0.3565,  ..., -0.0621, -0.5939, -0.1527]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vHB2lWf6i__v"
      },
      "source": [
        "model.to(device) #CNN to GPU\n",
        "\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SEwp_gS2jBT-"
      },
      "source": [
        "def binary_accuracy(preds, y):\n",
        "    \"\"\"\n",
        "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
        "    \"\"\"\n",
        "\n",
        "    #round predictions to the closest integer\n",
        "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
        "    correct = (rounded_preds == y).float() #convert into float for division \n",
        "    acc = correct.sum() / len(correct)\n",
        "    return acc"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k54_z7G6jCtE"
      },
      "source": [
        "# training function \n",
        "def train(model, iterator):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    model.train()\n",
        "    bar = pyprind.ProgBar(len(iterator), bar_char='█')\n",
        "    for batch in iterator:\n",
        "        \n",
        "        text, text_lengths = batch.text\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        predictions = model(text, text_lengths).squeeze(1)\n",
        "        loss = criterion(predictions, batch.tag)\n",
        "        acc = binary_accuracy(predictions, batch.tag)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "        \n",
        "        bar.update()\n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dz19pDSbjEFQ"
      },
      "source": [
        "def evaluate(model, iterator,mode):\n",
        "    \n",
        "    epoch_acc = 0\n",
        "    epoch_loss=0\n",
        "    preds,labels=[],[]\n",
        "    model.eval()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        bar = pyprind.ProgBar(len(iterator), bar_char='█')\n",
        "        for batch in iterator:\n",
        "            \n",
        "            text, text_lengths = batch.text\n",
        "            predictions = model(text, text_lengths).squeeze(1)\n",
        "            acc = binary_accuracy(predictions, batch.tag)\n",
        "            loss = criterion(predictions, batch.tag)\n",
        "            \n",
        "            rounded_preds = torch.round(torch.sigmoid(predictions))\n",
        "            logits = rounded_preds.detach().cpu().numpy()\n",
        "            label_ids = batch.tag.to('cpu').numpy()\n",
        "            \n",
        "            preds.append(logits)\n",
        "            labels.append(label_ids)\n",
        "\n",
        "            epoch_acc += acc.item()\n",
        "            epoch_loss+=loss.item()\n",
        "            bar.update()\n",
        "    if mode ==\"validation\":        \n",
        "      return epoch_acc / len(iterator),epoch_loss / len(iterator)\n",
        "    if mode ==\"testing\":\n",
        "      return epoch_acc / len(iterator),epoch_loss / len(iterator),preds,labels"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4u1w2vk8jFP-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43c96857-0ba1-42f5-d30e-675ce39ce56f"
      },
      "source": [
        "t = time.time()\n",
        "loss=[]\n",
        "acc=[]\n",
        "val_acc=[]\n",
        "val_loss=[]\n",
        "same_loss_count=0\n",
        "prev_loss = 0\n",
        "for epoch in range(num_epochs):\n",
        "    print(f'Epoch Number: {epoch}\\n')\n",
        "    train_loss, train_acc = train(model, train_iterator)\n",
        "    valid_acc,valid_loss = evaluate(model, valid_iterator,\"validation\")\n",
        "\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\tVal. Loss: {valid_loss:.3f} | Val. Acc: {valid_acc*100:.2f}%')\n",
        "    \n",
        "    #print(f'\\t Val. Acc: {valid_acc*100:.2f}%')\n",
        "    \n",
        "    loss.append(train_loss)\n",
        "    acc.append(train_acc)\n",
        "    val_acc.append(valid_acc)\n",
        "    val_loss.append(valid_loss)\n",
        "    \n",
        "    if np.abs(prev_loss-valid_loss)<0.001:\n",
        "      same_loss_count+=1\n",
        "\n",
        "    prev_loss=valid_loss\n",
        "    if same_loss_count == 3:\n",
        "      break\n",
        "      \n",
        "print(f'time:{time.time()-t:.3f}')"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch Number: 0\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchtext/data/batch.py:23: UserWarning: Batch class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
            "  warnings.warn('{} class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.'.format(self.__class__.__name__), UserWarning)\n",
            "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
            "Total time elapsed: 00:01:06\n",
            "0% [██████████████████████████████] 100% | ETA: 00:00:00"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\tTrain Loss: 0.606 | Train Acc: 65.77%\n",
            "\tVal. Loss: 0.545 | Val. Acc: 71.98%\n",
            "Epoch Number: 1\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Total time elapsed: 00:00:01\n",
            "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
            "Total time elapsed: 00:01:06\n",
            "0% [██████████████████████████████] 100% | ETA: 00:00:00"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\tTrain Loss: 0.441 | Train Acc: 77.59%\n",
            "\tVal. Loss: 0.540 | Val. Acc: 73.06%\n",
            "Epoch Number: 2\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Total time elapsed: 00:00:01\n",
            "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
            "Total time elapsed: 00:01:05\n",
            "0% [██████████████████████████████] 100% | ETA: 00:00:00"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\tTrain Loss: 0.330 | Train Acc: 83.45%\n",
            "\tVal. Loss: 0.566 | Val. Acc: 72.39%\n",
            "Epoch Number: 3\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Total time elapsed: 00:00:01\n",
            "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
            "Total time elapsed: 00:01:05\n",
            "0% [██████████████████████████████] 100% | ETA: 00:00:00"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\tTrain Loss: 0.244 | Train Acc: 87.36%\n",
            "\tVal. Loss: 0.724 | Val. Acc: 71.74%\n",
            "Epoch Number: 4\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Total time elapsed: 00:00:01\n",
            "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
            "Total time elapsed: 00:01:06\n",
            "0% [██████████████████████████████] 100% | ETA: 00:00:00"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\tTrain Loss: 0.183 | Train Acc: 90.32%\n",
            "\tVal. Loss: 0.900 | Val. Acc: 70.71%\n",
            "time:337.496\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Total time elapsed: 00:00:01\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B7ffMDNrxAqw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "outputId": "237e5ddb-9760-4ec7-c3b2-134ad8f62cd2"
      },
      "source": [
        "plt.xlabel(\"runs\")\n",
        "plt.ylabel(\"normalised measure of loss/accuracy\")\n",
        "x_len=list(range(len(val_loss)))\n",
        "plt.axis([0, max(x_len), 0, 1])\n",
        "plt.title('result of LSTM')\n",
        "loss=np.asarray(loss)/max(loss)\n",
        "plt.plot(x_len, loss, 'r+',label=\"loss\")\n",
        "plt.plot(x_len, acc, 'b.', label=\"accuracy\")\n",
        "plt.plot(x_len, val_acc, 'g.', label=\"val_accuracy\")\n",
        "plt.plot(x_len, val_loss, 'g+', label=\"val_loss\")\n",
        "\n",
        "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.2)\n",
        "plt.show"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function matplotlib.pyplot.show>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "46ZsNjmvogTU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "359c2766-0e0c-4278-bf1c-69821dbb96ac"
      },
      "source": [
        "test_acc,test_loss,preds,labels = evaluate(model, test_iterator,\"testing\")"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchtext/data/batch.py:23: UserWarning: Batch class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
            "  warnings.warn('{} class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.'.format(self.__class__.__name__), UserWarning)\n",
            "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
            "Total time elapsed: 00:00:01\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CXpOQhrsbQ-n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "328656db-600d-4659-add5-482c2df928f1"
      },
      "source": [
        "print(f'\\tTest Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\tTest Loss: 0.950 | Test Acc: 70.29%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WxbhHS07Gkc2"
      },
      "source": [
        "preds = np.concatenate(preds)\n",
        "labels = np.concatenate(labels)\n",
        "\n",
        "prc,rec,fs = precision_score(labels,preds),recall_score(labels,preds),f1_score(labels,preds)"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ndBHajOggWD7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43e88882-6b0e-4478-f7b9-04ac859e6b0c"
      },
      "source": [
        "print(f'\\tTest Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}% | Precision: {prc*100:.2f}% | Recall: {rec*100:.2f}% | F1-Score: {fs*100:.2f}%')"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\tTest Loss: 0.950 | Test Acc: 70.29% | Precision: 67.97% | Recall: 75.39% | F1-Score: 71.49%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XM1rrkYNqSGj"
      },
      "source": [
        "# For Setting2: \n",
        "**Hyperparameters:**\n",
        "*   Epoch number=10\n",
        "*   Learning rate=0.001\n",
        "*   batch size= 8\n",
        "*   Number of nodes in hidden layer = 150"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZIdPO1LuvGWy",
        "outputId": "d404c78d-e8db-4689-b0f4-0ac20382e90e"
      },
      "source": [
        "# Hyperparameters\n",
        "num_epochs = 10\n",
        "learning_rate = 0.001\n",
        "\n",
        "INPUT_DIM = len(TEXT.vocab)\n",
        "EMBEDDING_DIM = 300\n",
        "HIDDEN_DIM = 150\n",
        "OUTPUT_DIM = 1\n",
        "#N_LAYERS = 2\n",
        "BIDIRECTIONAL = True\n",
        "DROPOUT = 0.1\n",
        "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token] # padding\n",
        "BATCH_SIZE = 8\n",
        "\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)\n",
        "# keep in mind the sort_key option \n",
        "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
        "    (train_data, valid_data, test_data), sort_key=lambda x: len(x.text),sort_within_batch = True,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    device=device)\n",
        "\n",
        "class LSTM_net(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim,\n",
        "                 bidirectional, dropout, pad_idx):\n",
        "        \n",
        "        super().__init__()\n",
        "        \n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx = pad_idx)\n",
        "        \n",
        "        self.rnn = nn.LSTM(embedding_dim, \n",
        "                           hidden_dim, \n",
        "                           bidirectional=bidirectional, \n",
        "                           dropout=dropout)\n",
        "        \n",
        "        self.fc1 = nn.Linear(hidden_dim * 2, hidden_dim)\n",
        "        \n",
        "        self.fc2 = nn.Linear(hidden_dim, 1)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, text, text_lengths):\n",
        "        \n",
        "        # text = [sent len, batch size]\n",
        "        \n",
        "        embedded = self.embedding(text)\n",
        "        \n",
        "        # embedded = [sent len, batch size, emb dim]\n",
        "        \n",
        "        #pack sequence\n",
        "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, text_lengths)\n",
        "        \n",
        "        packed_output, (hidden, cell) = self.rnn(packed_embedded)\n",
        "        \n",
        "        #unpack sequence\n",
        "        # output, output_lengths = nn.utils.rnn.pad_packed_sequence(packed_output)\n",
        "\n",
        "        # output = [sent len, batch size, hid dim * num directions]\n",
        "        # output over padding tokens are zero tensors\n",
        "        \n",
        "        # hidden = [num layers * num directions, batch size, hid dim]\n",
        "        # cell = [num layers * num directions, batch size, hid dim]\n",
        "        \n",
        "        # concat the final forward (hidden[-2,:,:]) and backward (hidden[-1,:,:]) hidden layers\n",
        "        # and apply dropout\n",
        "        \n",
        "        hidden = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1))\n",
        "        output = self.fc1(hidden)\n",
        "        output = self.dropout(self.fc2(output))\n",
        "                \n",
        "        #hidden = [batch size, hid dim * num directions]\n",
        "            \n",
        "        return output\n",
        "\n",
        "#creating instance of our LSTM_net class\n",
        "\n",
        "model = LSTM_net(INPUT_DIM, \n",
        "            EMBEDDING_DIM, \n",
        "            HIDDEN_DIM, \n",
        "            OUTPUT_DIM,  \n",
        "            BIDIRECTIONAL, \n",
        "            DROPOUT, \n",
        "            PAD_IDX)\n",
        "\n",
        "pretrained_embeddings = TEXT.vocab.vectors\n",
        "model.embedding.weight.data.copy_(pretrained_embeddings)\n",
        "\n",
        "#  to initiaise padded to zeros\n",
        "model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)\n",
        "\n",
        "\n",
        "model.to(device) #CNN to GPU\n",
        "# Loss and optimizer\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
        "\n",
        "def binary_accuracy(preds, y):\n",
        "    \"\"\"\n",
        "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
        "    \"\"\"\n",
        "\n",
        "    #round predictions to the closest integer\n",
        "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
        "    correct = (rounded_preds == y).float() #convert into float for division \n",
        "    acc = correct.sum() / len(correct)\n",
        "    return acc\n",
        "\n",
        "# training function \n",
        "def train(model, iterator):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    model.train()\n",
        "    bar = pyprind.ProgBar(len(iterator), bar_char='█')\n",
        "    for batch in iterator:\n",
        "        \n",
        "        text, text_lengths = batch.text\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        predictions = model(text, text_lengths).squeeze(1)\n",
        "        loss = criterion(predictions, batch.tag)\n",
        "        acc = binary_accuracy(predictions, batch.tag)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "        \n",
        "        bar.update()\n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
        "\n",
        "def evaluate(model, iterator,mode):\n",
        "    \n",
        "    epoch_acc = 0\n",
        "    epoch_loss=0\n",
        "    preds,labels=[],[]\n",
        "    model.eval()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        bar = pyprind.ProgBar(len(iterator), bar_char='█')\n",
        "        for batch in iterator:\n",
        "            \n",
        "            text, text_lengths = batch.text\n",
        "            predictions = model(text, text_lengths).squeeze(1)\n",
        "            acc = binary_accuracy(predictions, batch.tag)\n",
        "            loss = criterion(predictions, batch.tag)\n",
        "            \n",
        "            rounded_preds = torch.round(torch.sigmoid(predictions))\n",
        "            logits = rounded_preds.detach().cpu().numpy()\n",
        "            label_ids = batch.tag.to('cpu').numpy()\n",
        "            \n",
        "            preds.append(logits)\n",
        "            labels.append(label_ids)\n",
        "\n",
        "            epoch_acc += acc.item()\n",
        "            epoch_loss+=loss.item()\n",
        "            bar.update()\n",
        "    if mode ==\"validation\":        \n",
        "      return epoch_acc / len(iterator),epoch_loss / len(iterator)\n",
        "    if mode ==\"testing\":\n",
        "      return epoch_acc / len(iterator),epoch_loss / len(iterator),preds,labels\n",
        "\n",
        "t = time.time()\n",
        "loss=[]\n",
        "acc=[]\n",
        "val_acc=[]\n",
        "val_loss=[]\n",
        "same_loss_count=0\n",
        "prev_loss = 0\n",
        "for epoch in range(num_epochs):\n",
        "    print(f'Epoch Number: {epoch}\\n')\n",
        "    train_loss, train_acc = train(model, train_iterator)\n",
        "    valid_acc,valid_loss = evaluate(model, valid_iterator,\"validation\")\n",
        "\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\tVal. Loss: {valid_loss:.3f} | Val. Acc: {valid_acc*100:.2f}%')\n",
        "    \n",
        "    #print(f'\\t Val. Acc: {valid_acc*100:.2f}%')\n",
        "    \n",
        "    loss.append(train_loss)\n",
        "    acc.append(train_acc)\n",
        "    val_acc.append(valid_acc)\n",
        "    val_loss.append(valid_loss)\n",
        "    \n",
        "    if np.abs(prev_loss-valid_loss)<0.001:\n",
        "      same_loss_count+=1\n",
        "\n",
        "    prev_loss=valid_loss\n",
        "    if same_loss_count == 3:\n",
        "      break\n",
        "      \n",
        "print(f'time:{time.time()-t:.3f}')\n",
        "\n"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n",
            "Epoch Number: 0\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchtext/data/iterator.py:48: UserWarning: BucketIterator class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
            "  warnings.warn('{} class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.'.format(self.__class__.__name__), UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:60: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n",
            "/usr/local/lib/python3.7/dist-packages/torchtext/data/batch.py:23: UserWarning: Batch class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
            "  warnings.warn('{} class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.'.format(self.__class__.__name__), UserWarning)\n",
            "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
            "Total time elapsed: 00:01:06\n",
            "0% [██████████████████████████████] 100% | ETA: 00:00:00"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\tTrain Loss: 0.606 | Train Acc: 65.82%\n",
            "\tVal. Loss: 0.544 | Val. Acc: 72.74%\n",
            "Epoch Number: 1\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Total time elapsed: 00:00:01\n",
            "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
            "Total time elapsed: 00:01:06\n",
            "0% [██████████████████████████████] 100% | ETA: 00:00:00"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\tTrain Loss: 0.442 | Train Acc: 77.76%\n",
            "\tVal. Loss: 0.528 | Val. Acc: 73.32%\n",
            "Epoch Number: 2\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Total time elapsed: 00:00:01\n",
            "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
            "Total time elapsed: 00:01:06\n",
            "0% [██████████████████████████████] 100% | ETA: 00:00:00"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\tTrain Loss: 0.323 | Train Acc: 83.75%\n",
            "\tVal. Loss: 0.566 | Val. Acc: 73.22%\n",
            "Epoch Number: 3\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Total time elapsed: 00:00:01\n",
            "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
            "Total time elapsed: 00:01:06\n",
            "0% [██████████████████████████████] 100% | ETA: 00:00:00"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\tTrain Loss: 0.239 | Train Acc: 87.69%\n",
            "\tVal. Loss: 0.697 | Val. Acc: 72.22%\n",
            "Epoch Number: 4\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Total time elapsed: 00:00:01\n",
            "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
            "Total time elapsed: 00:01:06\n",
            "0% [██████████████████████████████] 100% | ETA: 00:00:00"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\tTrain Loss: 0.178 | Train Acc: 90.59%\n",
            "\tVal. Loss: 0.978 | Val. Acc: 70.68%\n",
            "Epoch Number: 5\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Total time elapsed: 00:00:01\n",
            "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
            "Total time elapsed: 00:01:06\n",
            "0% [██████████████████████████████] 100% | ETA: 00:00:00"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\tTrain Loss: 0.141 | Train Acc: 92.06%\n",
            "\tVal. Loss: 1.279 | Val. Acc: 71.09%\n",
            "Epoch Number: 6\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Total time elapsed: 00:00:01\n",
            "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
            "Total time elapsed: 00:01:06\n",
            "0% [██████████████████████████████] 100% | ETA: 00:00:00"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\tTrain Loss: 0.120 | Train Acc: 93.00%\n",
            "\tVal. Loss: 1.325 | Val. Acc: 71.18%\n",
            "Epoch Number: 7\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Total time elapsed: 00:00:01\n",
            "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
            "Total time elapsed: 00:01:06\n",
            "0% [██████████████████████████████] 100% | ETA: 00:00:00"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\tTrain Loss: 0.109 | Train Acc: 93.44%\n",
            "\tVal. Loss: 1.308 | Val. Acc: 69.84%\n",
            "Epoch Number: 8\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Total time elapsed: 00:00:01\n",
            "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
            "Total time elapsed: 00:01:06\n",
            "0% [██████████████████████████████] 100% | ETA: 00:00:00"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\tTrain Loss: 0.102 | Train Acc: 93.82%\n",
            "\tVal. Loss: 1.431 | Val. Acc: 70.59%\n",
            "Epoch Number: 9\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Total time elapsed: 00:00:01\n",
            "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
            "Total time elapsed: 00:01:06\n",
            "0% [██████████████████████████████] 100% | ETA: 00:00:00"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\tTrain Loss: 0.098 | Train Acc: 93.82%\n",
            "\tVal. Loss: 1.231 | Val. Acc: 69.46%\n",
            "time:677.653\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Total time elapsed: 00:00:01\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "TqjijsQDxHGh",
        "outputId": "0cedc7a6-1d9b-46b8-d961-6efbcf72937a"
      },
      "source": [
        "plt.xlabel(\"runs\")\n",
        "plt.ylabel(\"normalised measure of loss/accuracy\")\n",
        "x_len=list(range(len(val_loss)))\n",
        "plt.axis([0, max(x_len), 0, 1])\n",
        "plt.title('result of LSTM')\n",
        "loss=np.asarray(loss)/max(loss)\n",
        "plt.plot(x_len, loss, 'r+',label=\"loss\")\n",
        "plt.plot(x_len, acc, 'b.', label=\"accuracy\")\n",
        "plt.plot(x_len, val_acc, 'g.', label=\"val_accuracy\")\n",
        "plt.plot(x_len, val_loss, 'g+', label=\"val_loss\")\n",
        "\n",
        "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.2)\n",
        "plt.show\n",
        "\n",
        "\n",
        "test_acc,test_loss,preds,labels = evaluate(model, test_iterator,\"testing\")\n",
        "\n",
        "print(f'\\tTest Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')\n",
        "preds = np.concatenate(preds)\n",
        "labels = np.concatenate(labels)\n",
        "\n",
        "prc,rec,fs = precision_score(labels,preds),recall_score(labels,preds),f1_score(labels,preds)\n",
        "print(f'\\tTest Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}% | Precision: {prc*100:.2f}% | Recall: {rec*100:.2f}% | F1-Score: {fs*100:.2f}%')"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchtext/data/batch.py:23: UserWarning: Batch class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
            "  warnings.warn('{} class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.'.format(self.__class__.__name__), UserWarning)\n",
            "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
            "Total time elapsed: 00:00:01\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\tTest Loss: 1.282 | Test Acc: 68.54%\n",
            "\tTest Loss: 1.282 | Test Acc: 68.54% | Precision: 69.25% | Recall: 65.35% | F1-Score: 67.25%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YgLCnyLdSSQm"
      },
      "source": [
        "# For Setting3: \n",
        "**Hyperparameters:**\n",
        "*   Epoch number=15\n",
        "*   Learning rate=0.001\n",
        "*   batch size= 8\n",
        "*   Number of nodes in hidden layer = 200"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rbp9qQgsSf_f",
        "outputId": "7186aa75-6728-407e-ee7b-d2f3aaf0119e"
      },
      "source": [
        "# Hyperparameters\n",
        "num_epochs = 15\n",
        "learning_rate = 0.001\n",
        "\n",
        "INPUT_DIM = len(TEXT.vocab)\n",
        "EMBEDDING_DIM = 300\n",
        "HIDDEN_DIM = 200\n",
        "OUTPUT_DIM = 1\n",
        "#N_LAYERS = 2\n",
        "BIDIRECTIONAL = True\n",
        "DROPOUT = 0.1\n",
        "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token] # padding\n",
        "BATCH_SIZE = 8\n",
        "\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)\n",
        "# keep in mind the sort_key option \n",
        "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
        "    (train_data, valid_data, test_data), sort_key=lambda x: len(x.text),sort_within_batch = True,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    device=device)\n",
        "\n",
        "class LSTM_net(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim,\n",
        "                 bidirectional, dropout, pad_idx):\n",
        "        \n",
        "        super().__init__()\n",
        "        \n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx = pad_idx)\n",
        "        \n",
        "        self.rnn = nn.LSTM(embedding_dim, \n",
        "                           hidden_dim, \n",
        "                           bidirectional=bidirectional, \n",
        "                           dropout=dropout)\n",
        "        \n",
        "        self.fc1 = nn.Linear(hidden_dim * 2, hidden_dim)\n",
        "        \n",
        "        self.fc2 = nn.Linear(hidden_dim, 1)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, text, text_lengths):\n",
        "        \n",
        "        # text = [sent len, batch size]\n",
        "        \n",
        "        embedded = self.embedding(text)\n",
        "        \n",
        "        # embedded = [sent len, batch size, emb dim]\n",
        "        \n",
        "        #pack sequence\n",
        "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, text_lengths)\n",
        "        \n",
        "        packed_output, (hidden, cell) = self.rnn(packed_embedded)\n",
        "        \n",
        "        #unpack sequence\n",
        "        # output, output_lengths = nn.utils.rnn.pad_packed_sequence(packed_output)\n",
        "\n",
        "        # output = [sent len, batch size, hid dim * num directions]\n",
        "        # output over padding tokens are zero tensors\n",
        "        \n",
        "        # hidden = [num layers * num directions, batch size, hid dim]\n",
        "        # cell = [num layers * num directions, batch size, hid dim]\n",
        "        \n",
        "        # concat the final forward (hidden[-2,:,:]) and backward (hidden[-1,:,:]) hidden layers\n",
        "        # and apply dropout\n",
        "        \n",
        "        hidden = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1))\n",
        "        output = self.fc1(hidden)\n",
        "        output = self.dropout(self.fc2(output))\n",
        "                \n",
        "        #hidden = [batch size, hid dim * num directions]\n",
        "            \n",
        "        return output\n",
        "\n",
        "#creating instance of our LSTM_net class\n",
        "\n",
        "model = LSTM_net(INPUT_DIM, \n",
        "            EMBEDDING_DIM, \n",
        "            HIDDEN_DIM, \n",
        "            OUTPUT_DIM,  \n",
        "            BIDIRECTIONAL, \n",
        "            DROPOUT, \n",
        "            PAD_IDX)\n",
        "\n",
        "pretrained_embeddings = TEXT.vocab.vectors\n",
        "model.embedding.weight.data.copy_(pretrained_embeddings)\n",
        "\n",
        "#  to initiaise padded to zeros\n",
        "model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)\n",
        "\n",
        "\n",
        "model.to(device) #CNN to GPU\n",
        "# Loss and optimizer\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
        "\n",
        "def binary_accuracy(preds, y):\n",
        "    \"\"\"\n",
        "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
        "    \"\"\"\n",
        "\n",
        "    #round predictions to the closest integer\n",
        "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
        "    correct = (rounded_preds == y).float() #convert into float for division \n",
        "    acc = correct.sum() / len(correct)\n",
        "    return acc\n",
        "\n",
        "# training function \n",
        "def train(model, iterator):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    model.train()\n",
        "    bar = pyprind.ProgBar(len(iterator), bar_char='█')\n",
        "    for batch in iterator:\n",
        "        \n",
        "        text, text_lengths = batch.text\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        predictions = model(text, text_lengths).squeeze(1)\n",
        "        loss = criterion(predictions, batch.tag)\n",
        "        acc = binary_accuracy(predictions, batch.tag)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "        \n",
        "        bar.update()\n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
        "\n",
        "def evaluate(model, iterator,mode):\n",
        "    \n",
        "    epoch_acc = 0\n",
        "    epoch_loss=0\n",
        "    preds,labels=[],[]\n",
        "    model.eval()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        bar = pyprind.ProgBar(len(iterator), bar_char='█')\n",
        "        for batch in iterator:\n",
        "            \n",
        "            text, text_lengths = batch.text\n",
        "            predictions = model(text, text_lengths).squeeze(1)\n",
        "            acc = binary_accuracy(predictions, batch.tag)\n",
        "            loss = criterion(predictions, batch.tag)\n",
        "            \n",
        "            rounded_preds = torch.round(torch.sigmoid(predictions))\n",
        "            logits = rounded_preds.detach().cpu().numpy()\n",
        "            label_ids = batch.tag.to('cpu').numpy()\n",
        "            \n",
        "            preds.append(logits)\n",
        "            labels.append(label_ids)\n",
        "\n",
        "            epoch_acc += acc.item()\n",
        "            epoch_loss+=loss.item()\n",
        "            bar.update()\n",
        "    if mode ==\"validation\":        \n",
        "      return epoch_acc / len(iterator),epoch_loss / len(iterator)\n",
        "    if mode ==\"testing\":\n",
        "      return epoch_acc / len(iterator),epoch_loss / len(iterator),preds,labels\n",
        "\n",
        "t = time.time()\n",
        "loss=[]\n",
        "acc=[]\n",
        "val_acc=[]\n",
        "val_loss=[]\n",
        "same_loss_count=0\n",
        "prev_loss = 0\n",
        "for epoch in range(num_epochs):\n",
        "    print(f'Epoch Number: {epoch}\\n')\n",
        "    train_loss, train_acc = train(model, train_iterator)\n",
        "    valid_acc,valid_loss = evaluate(model, valid_iterator,\"validation\")\n",
        "\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\tVal. Loss: {valid_loss:.3f} | Val. Acc: {valid_acc*100:.2f}%')\n",
        "    \n",
        "    #print(f'\\t Val. Acc: {valid_acc*100:.2f}%')\n",
        "    \n",
        "    loss.append(train_loss)\n",
        "    acc.append(train_acc)\n",
        "    val_acc.append(valid_acc)\n",
        "    val_loss.append(valid_loss)\n",
        "    \n",
        "    if np.abs(prev_loss-valid_loss)<0.001:\n",
        "      same_loss_count+=1\n",
        "\n",
        "    prev_loss=valid_loss\n",
        "    if same_loss_count == 3:\n",
        "      break\n",
        "      \n",
        "print(f'time:{time.time()-t:.3f}')\n",
        "\n"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n",
            "Epoch Number: 0\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchtext/data/iterator.py:48: UserWarning: BucketIterator class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
            "  warnings.warn('{} class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.'.format(self.__class__.__name__), UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:60: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n",
            "/usr/local/lib/python3.7/dist-packages/torchtext/data/batch.py:23: UserWarning: Batch class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
            "  warnings.warn('{} class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.'.format(self.__class__.__name__), UserWarning)\n",
            "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
            "Total time elapsed: 00:01:06\n",
            "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
            "Total time elapsed: 00:00:01\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\tTrain Loss: 0.606 | Train Acc: 65.71%\n",
            "\tVal. Loss: 0.541 | Val. Acc: 72.14%\n",
            "Epoch Number: 1\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
            "Total time elapsed: 00:01:06\n",
            "0% [██████████████████████████████] 100% | ETA: 00:00:00"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\tTrain Loss: 0.443 | Train Acc: 77.64%\n",
            "\tVal. Loss: 0.525 | Val. Acc: 73.22%\n",
            "Epoch Number: 2\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Total time elapsed: 00:00:01\n",
            "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
            "Total time elapsed: 00:01:06\n",
            "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
            "Total time elapsed: 00:00:01\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\tTrain Loss: 0.329 | Train Acc: 83.49%\n",
            "\tVal. Loss: 0.560 | Val. Acc: 71.98%\n",
            "Epoch Number: 3\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
            "Total time elapsed: 00:01:07\n",
            "0% [██████████████████████████████] 100% | ETA: 00:00:00"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\tTrain Loss: 0.244 | Train Acc: 87.67%\n",
            "\tVal. Loss: 0.723 | Val. Acc: 72.03%\n",
            "Epoch Number: 4\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Total time elapsed: 00:00:01\n",
            "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
            "Total time elapsed: 00:01:08\n",
            "0% [██████████████████████████████] 100% | ETA: 00:00:00"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\tTrain Loss: 0.182 | Train Acc: 90.36%\n",
            "\tVal. Loss: 0.883 | Val. Acc: 69.82%\n",
            "Epoch Number: 5\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Total time elapsed: 00:00:01\n",
            "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
            "Total time elapsed: 00:01:07\n",
            "0% [██████████████████████████████] 100% | ETA: 00:00:00"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\tTrain Loss: 0.143 | Train Acc: 92.15%\n",
            "\tVal. Loss: 0.996 | Val. Acc: 69.65%\n",
            "Epoch Number: 6\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Total time elapsed: 00:00:01\n",
            "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
            "Total time elapsed: 00:01:06\n",
            "0% [██████████████████████████████] 100% | ETA: 00:00:00"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\tTrain Loss: 0.123 | Train Acc: 92.89%\n",
            "\tVal. Loss: 1.260 | Val. Acc: 70.06%\n",
            "Epoch Number: 7\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Total time elapsed: 00:00:01\n",
            "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
            "Total time elapsed: 00:01:06\n",
            "0% [██████████████████████████████] 100% | ETA: 00:00:00"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\tTrain Loss: 0.111 | Train Acc: 93.44%\n",
            "\tVal. Loss: 1.186 | Val. Acc: 69.10%\n",
            "Epoch Number: 8\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Total time elapsed: 00:00:01\n",
            "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
            "Total time elapsed: 00:01:06\n",
            "0% [██████████████████████████████] 100% | ETA: 00:00:00"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\tTrain Loss: 0.102 | Train Acc: 93.94%\n",
            "\tVal. Loss: 1.427 | Val. Acc: 68.71%\n",
            "Epoch Number: 9\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Total time elapsed: 00:00:01\n",
            "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
            "Total time elapsed: 00:01:06\n",
            "0% [██████████████████████████████] 100% | ETA: 00:00:00"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\tTrain Loss: 0.101 | Train Acc: 93.62%\n",
            "\tVal. Loss: 1.870 | Val. Acc: 69.14%\n",
            "Epoch Number: 10\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Total time elapsed: 00:00:01\n",
            "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
            "Total time elapsed: 00:01:06\n",
            "0% [██████████████████████████████] 100% | ETA: 00:00:00"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\tTrain Loss: 0.094 | Train Acc: 94.11%\n",
            "\tVal. Loss: 1.971 | Val. Acc: 69.72%\n",
            "Epoch Number: 11\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Total time elapsed: 00:00:01\n",
            "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
            "Total time elapsed: 00:01:06\n",
            "0% [██████████████████████████████] 100% | ETA: 00:00:00"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\tTrain Loss: 0.095 | Train Acc: 94.04%\n",
            "\tVal. Loss: 1.609 | Val. Acc: 68.48%\n",
            "Epoch Number: 12\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Total time elapsed: 00:00:01\n",
            "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
            "Total time elapsed: 00:01:06\n",
            "0% [██████████████████████████████] 100% | ETA: 00:00:00"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\tTrain Loss: 0.091 | Train Acc: 94.32%\n",
            "\tVal. Loss: 1.653 | Val. Acc: 69.65%\n",
            "Epoch Number: 13\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Total time elapsed: 00:00:01\n",
            "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
            "Total time elapsed: 00:01:06\n",
            "0% [██████████████████████████████] 100% | ETA: 00:00:00"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\tTrain Loss: 0.093 | Train Acc: 94.03%\n",
            "\tVal. Loss: 1.851 | Val. Acc: 68.86%\n",
            "Epoch Number: 14\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Total time elapsed: 00:00:01\n",
            "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
            "Total time elapsed: 00:01:06\n",
            "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
            "Total time elapsed: 00:00:01\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\tTrain Loss: 0.089 | Train Acc: 94.35%\n",
            "\tVal. Loss: 1.901 | Val. Acc: 68.66%\n",
            "time:1023.427\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "GAB7SYBsSwk4",
        "outputId": "e7d3dc78-e5f5-4e5d-867f-591aec11fe6e"
      },
      "source": [
        "plt.xlabel(\"runs\")\n",
        "plt.ylabel(\"normalised measure of loss/accuracy\")\n",
        "x_len=list(range(len(val_loss)))\n",
        "plt.axis([0, max(x_len), 0, 1])\n",
        "plt.title('result of LSTM')\n",
        "loss=np.asarray(loss)/max(loss)\n",
        "plt.plot(x_len, loss, 'r+',label=\"loss\")\n",
        "plt.plot(x_len, acc, 'b.', label=\"accuracy\")\n",
        "plt.plot(x_len, val_acc, 'g.', label=\"val_accuracy\")\n",
        "plt.plot(x_len, val_loss, 'g+', label=\"val_loss\")\n",
        "\n",
        "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.2)\n",
        "plt.show\n",
        "\n",
        "\n",
        "test_acc,test_loss,preds,labels = evaluate(model, test_iterator,\"testing\")\n",
        "\n",
        "print(f'\\tTest Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')\n",
        "preds = np.concatenate(preds)\n",
        "labels = np.concatenate(labels)\n",
        "\n",
        "prc,rec,fs = precision_score(labels,preds),recall_score(labels,preds),f1_score(labels,preds)\n",
        "print(f'\\tTest Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}% | Precision: {prc*100:.2f}% | Recall: {rec*100:.2f}% | F1-Score: {fs*100:.2f}%')"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchtext/data/batch.py:23: UserWarning: Batch class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
            "  warnings.warn('{} class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.'.format(self.__class__.__name__), UserWarning)\n",
            "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
            "Total time elapsed: 00:00:01\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\tTest Loss: 1.913 | Test Acc: 69.10%\n",
            "\tTest Loss: 1.913 | Test Acc: 69.10% | Precision: 70.26% | Recall: 64.95% | F1-Score: 67.50%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m6J4Iu_VUzP2"
      },
      "source": [
        "# For Setting4: \n",
        "**Hyperparameters:**\n",
        "*   Epoch number=6\n",
        "*   Learning rate=0.0005\n",
        "*   batch size= 16\n",
        "*   Number of nodes in hidden layer = 300"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k1Dwdqx1U98c",
        "outputId": "c5a4f302-6a11-44da-f176-38e70aac204b"
      },
      "source": [
        "# Hyperparameters\n",
        "num_epochs = 6\n",
        "learning_rate = 0.0005\n",
        "\n",
        "INPUT_DIM = len(TEXT.vocab)\n",
        "EMBEDDING_DIM = 300\n",
        "HIDDEN_DIM = 300\n",
        "OUTPUT_DIM = 1\n",
        "#N_LAYERS = 2\n",
        "BIDIRECTIONAL = True\n",
        "DROPOUT = 0.1\n",
        "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token] # padding\n",
        "BATCH_SIZE = 16\n",
        "\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)\n",
        "# keep in mind the sort_key option \n",
        "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
        "    (train_data, valid_data, test_data), sort_key=lambda x: len(x.text),sort_within_batch = True,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    device=device)\n",
        "\n",
        "class LSTM_net(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim,\n",
        "                 bidirectional, dropout, pad_idx):\n",
        "        \n",
        "        super().__init__()\n",
        "        \n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx = pad_idx)\n",
        "        \n",
        "        self.rnn = nn.LSTM(embedding_dim, \n",
        "                           hidden_dim, \n",
        "                           bidirectional=bidirectional, \n",
        "                           dropout=dropout)\n",
        "        \n",
        "        self.fc1 = nn.Linear(hidden_dim * 2, hidden_dim)\n",
        "        \n",
        "        self.fc2 = nn.Linear(hidden_dim, 1)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, text, text_lengths):\n",
        "        \n",
        "        # text = [sent len, batch size]\n",
        "        \n",
        "        embedded = self.embedding(text)\n",
        "        \n",
        "        # embedded = [sent len, batch size, emb dim]\n",
        "        \n",
        "        #pack sequence\n",
        "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, text_lengths)\n",
        "        \n",
        "        packed_output, (hidden, cell) = self.rnn(packed_embedded)\n",
        "        \n",
        "        #unpack sequence\n",
        "        # output, output_lengths = nn.utils.rnn.pad_packed_sequence(packed_output)\n",
        "\n",
        "        # output = [sent len, batch size, hid dim * num directions]\n",
        "        # output over padding tokens are zero tensors\n",
        "        \n",
        "        # hidden = [num layers * num directions, batch size, hid dim]\n",
        "        # cell = [num layers * num directions, batch size, hid dim]\n",
        "        \n",
        "        # concat the final forward (hidden[-2,:,:]) and backward (hidden[-1,:,:]) hidden layers\n",
        "        # and apply dropout\n",
        "        \n",
        "        hidden = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1))\n",
        "        output = self.fc1(hidden)\n",
        "        output = self.dropout(self.fc2(output))\n",
        "                \n",
        "        #hidden = [batch size, hid dim * num directions]\n",
        "            \n",
        "        return output\n",
        "\n",
        "#creating instance of our LSTM_net class\n",
        "\n",
        "model = LSTM_net(INPUT_DIM, \n",
        "            EMBEDDING_DIM, \n",
        "            HIDDEN_DIM, \n",
        "            OUTPUT_DIM,  \n",
        "            BIDIRECTIONAL, \n",
        "            DROPOUT, \n",
        "            PAD_IDX)\n",
        "\n",
        "pretrained_embeddings = TEXT.vocab.vectors\n",
        "model.embedding.weight.data.copy_(pretrained_embeddings)\n",
        "\n",
        "#  to initiaise padded to zeros\n",
        "model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)\n",
        "\n",
        "\n",
        "model.to(device) #CNN to GPU\n",
        "# Loss and optimizer\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
        "\n",
        "def binary_accuracy(preds, y):\n",
        "    \"\"\"\n",
        "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
        "    \"\"\"\n",
        "\n",
        "    #round predictions to the closest integer\n",
        "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
        "    correct = (rounded_preds == y).float() #convert into float for division \n",
        "    acc = correct.sum() / len(correct)\n",
        "    return acc\n",
        "\n",
        "# training function \n",
        "def train(model, iterator):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    model.train()\n",
        "    bar = pyprind.ProgBar(len(iterator), bar_char='█')\n",
        "    for batch in iterator:\n",
        "        \n",
        "        text, text_lengths = batch.text\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        predictions = model(text, text_lengths).squeeze(1)\n",
        "        loss = criterion(predictions, batch.tag)\n",
        "        acc = binary_accuracy(predictions, batch.tag)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "        \n",
        "        bar.update()\n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
        "\n",
        "def evaluate(model, iterator,mode):\n",
        "    \n",
        "    epoch_acc = 0\n",
        "    epoch_loss=0\n",
        "    preds,labels=[],[]\n",
        "    model.eval()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        bar = pyprind.ProgBar(len(iterator), bar_char='█')\n",
        "        for batch in iterator:\n",
        "            \n",
        "            text, text_lengths = batch.text\n",
        "            predictions = model(text, text_lengths).squeeze(1)\n",
        "            acc = binary_accuracy(predictions, batch.tag)\n",
        "            loss = criterion(predictions, batch.tag)\n",
        "            \n",
        "            rounded_preds = torch.round(torch.sigmoid(predictions))\n",
        "            logits = rounded_preds.detach().cpu().numpy()\n",
        "            label_ids = batch.tag.to('cpu').numpy()\n",
        "            \n",
        "            preds.append(logits)\n",
        "            labels.append(label_ids)\n",
        "\n",
        "            epoch_acc += acc.item()\n",
        "            epoch_loss+=loss.item()\n",
        "            bar.update()\n",
        "    if mode ==\"validation\":        \n",
        "      return epoch_acc / len(iterator),epoch_loss / len(iterator)\n",
        "    if mode ==\"testing\":\n",
        "      return epoch_acc / len(iterator),epoch_loss / len(iterator),preds,labels\n",
        "\n",
        "t = time.time()\n",
        "loss=[]\n",
        "acc=[]\n",
        "val_acc=[]\n",
        "val_loss=[]\n",
        "same_loss_count=0\n",
        "prev_loss = 0\n",
        "for epoch in range(num_epochs):\n",
        "    print(f'Epoch Number: {epoch}\\n')\n",
        "    train_loss, train_acc = train(model, train_iterator)\n",
        "    valid_acc,valid_loss = evaluate(model, valid_iterator,\"validation\")\n",
        "\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\tVal. Loss: {valid_loss:.3f} | Val. Acc: {valid_acc*100:.2f}%')\n",
        "    \n",
        "    #print(f'\\t Val. Acc: {valid_acc*100:.2f}%')\n",
        "    \n",
        "    loss.append(train_loss)\n",
        "    acc.append(train_acc)\n",
        "    val_acc.append(valid_acc)\n",
        "    val_loss.append(valid_loss)\n",
        "    \n",
        "    if np.abs(prev_loss-valid_loss)<0.001:\n",
        "      same_loss_count+=1\n",
        "\n",
        "    prev_loss=valid_loss\n",
        "    if same_loss_count == 3:\n",
        "      break\n",
        "      \n",
        "print(f'time:{time.time()-t:.3f}')\n",
        "\n"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n",
            "Epoch Number: 0\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchtext/data/iterator.py:48: UserWarning: BucketIterator class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
            "  warnings.warn('{} class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.'.format(self.__class__.__name__), UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:60: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n",
            "/usr/local/lib/python3.7/dist-packages/torchtext/data/batch.py:23: UserWarning: Batch class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
            "  warnings.warn('{} class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.'.format(self.__class__.__name__), UserWarning)\n",
            "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
            "Total time elapsed: 00:00:35\n",
            "0% [██████████████████████████████] 100% | ETA: 00:00:00"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\tTrain Loss: 0.627 | Train Acc: 63.74%\n",
            "\tVal. Loss: 0.576 | Val. Acc: 70.70%\n",
            "Epoch Number: 1\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Total time elapsed: 00:00:00\n",
            "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
            "Total time elapsed: 00:00:34\n",
            "0% [██████████████████████████████] 100% | ETA: 00:00:00"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\tTrain Loss: 0.491 | Train Acc: 74.87%\n",
            "\tVal. Loss: 0.534 | Val. Acc: 72.16%\n",
            "Epoch Number: 2\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Total time elapsed: 00:00:00\n",
            "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
            "Total time elapsed: 00:00:34\n",
            "0% [██████████████████████████████] 100% | ETA: 00:00:00"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\tTrain Loss: 0.386 | Train Acc: 80.66%\n",
            "\tVal. Loss: 0.569 | Val. Acc: 72.50%\n",
            "Epoch Number: 3\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Total time elapsed: 00:00:00\n",
            "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
            "Total time elapsed: 00:00:34\n",
            "0% [██████████████████████████████] 100% | ETA: 00:00:00"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\tTrain Loss: 0.305 | Train Acc: 84.59%\n",
            "\tVal. Loss: 0.619 | Val. Acc: 71.68%\n",
            "Epoch Number: 4\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Total time elapsed: 00:00:00\n",
            "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
            "Total time elapsed: 00:00:34\n",
            "0% [██████████████████████████████] 100% | ETA: 00:00:00"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\tTrain Loss: 0.238 | Train Acc: 87.85%\n",
            "\tVal. Loss: 0.854 | Val. Acc: 71.64%\n",
            "Epoch Number: 5\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Total time elapsed: 00:00:00\n",
            "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
            "Total time elapsed: 00:00:34\n",
            "0% [██████████████████████████████] 100% | ETA: 00:00:00"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\tTrain Loss: 0.185 | Train Acc: 90.29%\n",
            "\tVal. Loss: 1.052 | Val. Acc: 70.63%\n",
            "time:213.973\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Total time elapsed: 00:00:00\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "0XNc0MZqU-PM",
        "outputId": "bd5b8f6f-8014-44aa-c30e-fd70a1e632c3"
      },
      "source": [
        "plt.xlabel(\"runs\")\n",
        "plt.ylabel(\"normalised measure of loss/accuracy\")\n",
        "x_len=list(range(len(val_loss)))\n",
        "plt.axis([0, max(x_len), 0, 1])\n",
        "plt.title('result of LSTM')\n",
        "loss=np.asarray(loss)/max(loss)\n",
        "plt.plot(x_len, loss, 'r+',label=\"loss\")\n",
        "plt.plot(x_len, acc, 'b.', label=\"accuracy\")\n",
        "plt.plot(x_len, val_acc, 'g.', label=\"val_accuracy\")\n",
        "plt.plot(x_len, val_loss, 'g+', label=\"val_loss\")\n",
        "\n",
        "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.2)\n",
        "plt.show\n",
        "\n",
        "\n",
        "test_acc,test_loss,preds,labels = evaluate(model, test_iterator,\"testing\")\n",
        "\n",
        "print(f'\\tTest Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')\n",
        "preds = np.concatenate(preds)\n",
        "labels = np.concatenate(labels)\n",
        "\n",
        "prc,rec,fs = precision_score(labels,preds),recall_score(labels,preds),f1_score(labels,preds)\n",
        "print(f'\\tTest Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}% | Precision: {prc*100:.2f}% | Recall: {rec*100:.2f}% | F1-Score: {fs*100:.2f}%')"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchtext/data/batch.py:23: UserWarning: Batch class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
            "  warnings.warn('{} class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.'.format(self.__class__.__name__), UserWarning)\n",
            "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
            "Total time elapsed: 00:00:00\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\tTest Loss: 1.124 | Test Acc: 69.78%\n",
            "\tTest Loss: 1.124 | Test Acc: 69.78% | Precision: 68.29% | Recall: 72.45% | F1-Score: 70.31%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "olStzvvHneiQ"
      },
      "source": [
        "# For Setting5: \n",
        "**Hyperparameters:**\n",
        "*   Epoch number=3\n",
        "*   Learning rate=0.0005\n",
        "*   batch size= 16\n",
        "*   Number of nodes in hidden layer = 500"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sqwrqlUknmjL",
        "outputId": "67934027-f7b9-412f-bc10-b90ac743e70b"
      },
      "source": [
        "# Hyperparameters\n",
        "num_epochs = 3\n",
        "learning_rate = 0.0005\n",
        "\n",
        "INPUT_DIM = len(TEXT.vocab)\n",
        "EMBEDDING_DIM = 300\n",
        "HIDDEN_DIM = 500\n",
        "OUTPUT_DIM = 1\n",
        "#N_LAYERS = 2\n",
        "BIDIRECTIONAL = True\n",
        "DROPOUT = 0.1\n",
        "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token] # padding\n",
        "BATCH_SIZE = 16\n",
        "\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)\n",
        "# keep in mind the sort_key option \n",
        "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
        "    (train_data, valid_data, test_data), sort_key=lambda x: len(x.text),sort_within_batch = True,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    device=device)\n",
        "\n",
        "class LSTM_net(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim,\n",
        "                 bidirectional, dropout, pad_idx):\n",
        "        \n",
        "        super().__init__()\n",
        "        \n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx = pad_idx)\n",
        "        \n",
        "        self.rnn = nn.LSTM(embedding_dim, \n",
        "                           hidden_dim, \n",
        "                           bidirectional=bidirectional, \n",
        "                           dropout=dropout)\n",
        "        \n",
        "        self.fc1 = nn.Linear(hidden_dim * 2, hidden_dim)\n",
        "        \n",
        "        self.fc2 = nn.Linear(hidden_dim, 1)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, text, text_lengths):\n",
        "        \n",
        "        # text = [sent len, batch size]\n",
        "        \n",
        "        embedded = self.embedding(text)\n",
        "        \n",
        "        # embedded = [sent len, batch size, emb dim]\n",
        "        \n",
        "        #pack sequence\n",
        "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, text_lengths)\n",
        "        \n",
        "        packed_output, (hidden, cell) = self.rnn(packed_embedded)\n",
        "        \n",
        "        #unpack sequence\n",
        "        # output, output_lengths = nn.utils.rnn.pad_packed_sequence(packed_output)\n",
        "\n",
        "        # output = [sent len, batch size, hid dim * num directions]\n",
        "        # output over padding tokens are zero tensors\n",
        "        \n",
        "        # hidden = [num layers * num directions, batch size, hid dim]\n",
        "        # cell = [num layers * num directions, batch size, hid dim]\n",
        "        \n",
        "        # concat the final forward (hidden[-2,:,:]) and backward (hidden[-1,:,:]) hidden layers\n",
        "        # and apply dropout\n",
        "        \n",
        "        hidden = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1))\n",
        "        output = self.fc1(hidden)\n",
        "        output = self.dropout(self.fc2(output))\n",
        "                \n",
        "        #hidden = [batch size, hid dim * num directions]\n",
        "            \n",
        "        return output\n",
        "\n",
        "#creating instance of our LSTM_net class\n",
        "\n",
        "model = LSTM_net(INPUT_DIM, \n",
        "            EMBEDDING_DIM, \n",
        "            HIDDEN_DIM, \n",
        "            OUTPUT_DIM,  \n",
        "            BIDIRECTIONAL, \n",
        "            DROPOUT, \n",
        "            PAD_IDX)\n",
        "\n",
        "pretrained_embeddings = TEXT.vocab.vectors\n",
        "model.embedding.weight.data.copy_(pretrained_embeddings)\n",
        "\n",
        "#  to initiaise padded to zeros\n",
        "model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)\n",
        "\n",
        "\n",
        "model.to(device) #CNN to GPU\n",
        "# Loss and optimizer\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
        "\n",
        "def binary_accuracy(preds, y):\n",
        "    \"\"\"\n",
        "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
        "    \"\"\"\n",
        "\n",
        "    #round predictions to the closest integer\n",
        "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
        "    correct = (rounded_preds == y).float() #convert into float for division \n",
        "    acc = correct.sum() / len(correct)\n",
        "    return acc\n",
        "\n",
        "# training function \n",
        "def train(model, iterator):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    model.train()\n",
        "    bar = pyprind.ProgBar(len(iterator), bar_char='█')\n",
        "    for batch in iterator:\n",
        "        \n",
        "        text, text_lengths = batch.text\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        predictions = model(text, text_lengths).squeeze(1)\n",
        "        loss = criterion(predictions, batch.tag)\n",
        "        acc = binary_accuracy(predictions, batch.tag)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "        \n",
        "        bar.update()\n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
        "\n",
        "def evaluate(model, iterator,mode):\n",
        "    \n",
        "    epoch_acc = 0\n",
        "    epoch_loss=0\n",
        "    preds,labels=[],[]\n",
        "    model.eval()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        bar = pyprind.ProgBar(len(iterator), bar_char='█')\n",
        "        for batch in iterator:\n",
        "            \n",
        "            text, text_lengths = batch.text\n",
        "            predictions = model(text, text_lengths).squeeze(1)\n",
        "            acc = binary_accuracy(predictions, batch.tag)\n",
        "            loss = criterion(predictions, batch.tag)\n",
        "            \n",
        "            rounded_preds = torch.round(torch.sigmoid(predictions))\n",
        "            logits = rounded_preds.detach().cpu().numpy()\n",
        "            label_ids = batch.tag.to('cpu').numpy()\n",
        "            \n",
        "            preds.append(logits)\n",
        "            labels.append(label_ids)\n",
        "\n",
        "            epoch_acc += acc.item()\n",
        "            epoch_loss+=loss.item()\n",
        "            bar.update()\n",
        "    if mode ==\"validation\":        \n",
        "      return epoch_acc / len(iterator),epoch_loss / len(iterator)\n",
        "    if mode ==\"testing\":\n",
        "      return epoch_acc / len(iterator),epoch_loss / len(iterator),preds,labels\n",
        "\n",
        "t = time.time()\n",
        "loss=[]\n",
        "acc=[]\n",
        "val_acc=[]\n",
        "val_loss=[]\n",
        "same_loss_count=0\n",
        "prev_loss = 0\n",
        "for epoch in range(num_epochs):\n",
        "    print(f'Epoch Number: {epoch}\\n')\n",
        "    train_loss, train_acc = train(model, train_iterator)\n",
        "    valid_acc,valid_loss = evaluate(model, valid_iterator,\"validation\")\n",
        "\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\tVal. Loss: {valid_loss:.3f} | Val. Acc: {valid_acc*100:.2f}%')\n",
        "    \n",
        "    #print(f'\\t Val. Acc: {valid_acc*100:.2f}%')\n",
        "    \n",
        "    loss.append(train_loss)\n",
        "    acc.append(train_acc)\n",
        "    val_acc.append(valid_acc)\n",
        "    val_loss.append(valid_loss)\n",
        "    \n",
        "    if np.abs(prev_loss-valid_loss)<0.001:\n",
        "      same_loss_count+=1\n",
        "\n",
        "    prev_loss=valid_loss\n",
        "    if same_loss_count == 3:\n",
        "      break\n",
        "      \n",
        "print(f'time:{time.time()-t:.3f}')\n",
        "\n"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n",
            "Epoch Number: 0\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchtext/data/iterator.py:48: UserWarning: BucketIterator class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
            "  warnings.warn('{} class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.'.format(self.__class__.__name__), UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:60: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n",
            "/usr/local/lib/python3.7/dist-packages/torchtext/data/batch.py:23: UserWarning: Batch class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
            "  warnings.warn('{} class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.'.format(self.__class__.__name__), UserWarning)\n",
            "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
            "Total time elapsed: 00:00:42\n",
            "0% [██████████████████████████████] 100% | ETA: 00:00:00"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\tTrain Loss: 0.626 | Train Acc: 63.91%\n",
            "\tVal. Loss: 0.560 | Val. Acc: 71.44%\n",
            "Epoch Number: 1\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Total time elapsed: 00:00:01\n",
            "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
            "Total time elapsed: 00:00:42\n",
            "0% [██████████████████████████████] 100% | ETA: 00:00:00"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\tTrain Loss: 0.490 | Train Acc: 74.71%\n",
            "\tVal. Loss: 0.531 | Val. Acc: 72.98%\n",
            "Epoch Number: 2\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Total time elapsed: 00:00:00\n",
            "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
            "Total time elapsed: 00:00:42\n",
            "0% [██████████████████████████████] 100% | ETA: 00:00:00"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\tTrain Loss: 0.381 | Train Acc: 80.86%\n",
            "\tVal. Loss: 0.599 | Val. Acc: 72.07%\n",
            "time:130.587\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Total time elapsed: 00:00:01\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "PKyUp_cxnmxj",
        "outputId": "26292e02-96c9-4817-9726-0a8ae46563c9"
      },
      "source": [
        "plt.xlabel(\"runs\")\n",
        "plt.ylabel(\"normalised measure of loss/accuracy\")\n",
        "x_len=list(range(len(val_loss)))\n",
        "plt.axis([0, max(x_len), 0, 1])\n",
        "plt.title('result of LSTM')\n",
        "loss=np.asarray(loss)/max(loss)\n",
        "plt.plot(x_len, loss, 'r+',label=\"loss\")\n",
        "plt.plot(x_len, acc, 'b.', label=\"accuracy\")\n",
        "plt.plot(x_len, val_acc, 'g.', label=\"val_accuracy\")\n",
        "plt.plot(x_len, val_loss, 'g+', label=\"val_loss\")\n",
        "\n",
        "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.2)\n",
        "plt.show\n",
        "\n",
        "\n",
        "test_acc,test_loss,preds,labels = evaluate(model, test_iterator,\"testing\")\n",
        "\n",
        "print(f'\\tTest Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')\n",
        "preds = np.concatenate(preds)\n",
        "labels = np.concatenate(labels)\n",
        "\n",
        "prc,rec,fs = precision_score(labels,preds),recall_score(labels,preds),f1_score(labels,preds)\n",
        "print(f'\\tTest Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}% | Precision: {prc*100:.2f}% | Recall: {rec*100:.2f}% | F1-Score: {fs*100:.2f}%')"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchtext/data/batch.py:23: UserWarning: Batch class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
            "  warnings.warn('{} class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.'.format(self.__class__.__name__), UserWarning)\n",
            "0% [██████████████████████████████] 100% | ETA: 00:00:00\n",
            "Total time elapsed: 00:00:01\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\tTest Loss: 0.618 | Test Acc: 71.64%\n",
            "\tTest Loss: 0.618 | Test Acc: 71.64% | Precision: 74.37% | Recall: 64.98% | F1-Score: 69.36%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}